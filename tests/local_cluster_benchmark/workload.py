#!/usr/bin/env python3
"""
workload.py – mixed 10 : 1 read / write stress for a local FoundationDB cluster
==============================================================================

• Uses the *raw* Python bindings you built yourself (no pip install).
• Detects the correct wire API version in three ways, in order:

    1.  `fdb._FDB_API_VERSION`             (newer builds)
    2.  `fdb/apiversion.py` ‑> `LATEST_API_VERSION` generated by `make`
    3.  Reads the same file manually and regex‑extracts the version

  If none are found it aborts — no hard‑coded 710/740 fallback.

• Starts `fdb.run_network()` so Futures resolve.
• Implements low‑level retry pattern with `on_error()`; prints live OPS/sec.

Typical run
-----------
python3 workload.py \
  --cluster_file /tmp/fdblocal/conf/fdb.cluster \
  --fdb-src  ~/fdb/build/bindings/python \
  --lib-dir  ~/fdb/build \
  --threads 8 --duration 90
"""
from __future__ import annotations
import argparse, importlib, os, re, random, string, sys, threading, time
from collections import Counter
from pathlib import Path

# ───────────── CLI args ──────────────────────────────────────────────────
cli = argparse.ArgumentParser()
cli.add_argument("--cluster_file", required=True, type=Path)
cli.add_argument("--threads",      default=4,  type=int)
cli.add_argument("--duration",     default=60, type=int)
cli.add_argument("--fdb-src",      type=Path, help="built bindings/python dir")
cli.add_argument("--lib-dir",      type=Path, help="dir containing libfdb_c.so")
args = cli.parse_args()

# ───────────── put your build on PYTHONPATH & linker path ────────────────
if args.fdb_src:
    sys.path.insert(0, str(args.fdb_src.resolve()))
if args.lib_dir:
    lib = args.lib_dir.resolve()
    os.environ["FDB_LIB_PATH"] = str(lib / "libfdb_c.so")
    ld_env = "DYLD_LIBRARY_PATH" if sys.platform == "darwin" else "LD_LIBRARY_PATH"
    os.environ[ld_env] = f"{lib}:{os.environ.get(ld_env,'')}"

import fdb, pathlib

# ───────────── detect API version without guessing ───────────────────────
def detect_api_version() -> int:
    # 1. attribute on C‑extension
    if hasattr(fdb, "_FDB_API_VERSION"):
        return fdb._FDB_API_VERSION

    # 2. generated Python module in build
    try:
        apiver = importlib.import_module("fdb.apiversion")
        return apiver.LATEST_API_VERSION  # type: ignore[attr-defined]
    except ModuleNotFoundError:
        pass

    # 3. read apiversion.py file directly
    fdb_dir = Path(fdb.__file__).parent
    ap_file = fdb_dir / "apiversion.py"
    if ap_file.exists():
        m = re.search(r"LATEST_API_VERSION\s*=\s*(\d+)", ap_file.read_text())
        if m:
            return int(m.group(1))

    raise RuntimeError("Cannot determine API version from built bindings")

fdb.api_version(detect_api_version())

# ───────────── start FDB network thread ──────────────────────────────────
net_thread = threading.Thread(target=fdb.run_network, daemon=True)
net_thread.start()

# ───────────── workload parameters & helpers ─────────────────────────────
PREFIX     = b"wl" + os.urandom(2)      # fresh range each run
KEY_COUNT  = 200_000
VAL_SIZE   = 256
RANGE_LEN  = 50
OPS_PER_TX = 12                         # ≈10 reads : 1 write

def rk() -> bytes:
    return PREFIX + f"{random.randint(0, KEY_COUNT-1):08d}".encode()

def rv() -> bytes:
    return "".join(random.choice(string.ascii_letters) for _ in range(VAL_SIZE)).encode()

# ───────────── worker thread ─────────────────────────────────────────────
def worker(db: "fdb.Database", agg: Counter, stop: threading.Event):
    while not stop.is_set():
        while True:                      # full txn retry loop
            tr = db.create_transaction()
            local = Counter()

            # populate txn
            for _ in range(OPS_PER_TX):
                r = random.random()
                if r < 0.66:             # GET
                    tr.get(rk()).wait(); local["get"] += 1
                elif r < 0.75:           # RANGE GET
                    s = rk()
                    list(tr.get_range(s, s+b"\xff", limit=RANGE_LEN).wait())
                    local["range_get"] += 1
                else:                    # write path
                    w = random.random()
                    if   w < 0.4: tr.set(rk(), rv()); local["set"] += 1
                    elif w < 0.7: tr.clear(rk());     local["clear"] += 1
                    else:  s = rk(); tr.clear_range(s, s+b"\xff"); local["range_clear"] += 1

            # commit with on_error retry
            while True:
                try:
                    tr.commit().wait(); break
                except fdb.FDBError as e:
                    tr = tr.on_error(e).wait(); continue  # back‑off then retry commit

            break  # commit succeeded → leave outer loop

        agg.update(local); agg["tx"] += 1; agg["ops"] += OPS_PER_TX

# ───────────── live reporter ─────────────────────────────────────────────
def reporter(agg: Counter, stop: threading.Event):
    last = 0
    while not stop.wait(1):
        cur = agg["ops"]; delta = cur - last; last = cur
        print(f"{delta:>7} ops/s   "
              f"G:{agg['get']} RG:{agg['range_get']} "
              f"S:{agg['set']} C:{agg['clear']} RC:{agg['range_clear']} "
              f"TX:{agg['tx']}", flush=True)

# ───────────── main │ spin threads, wait, shutdown ───────────────────────
def main():
    db   = fdb.open(str(args.cluster_file))
    agg  = Counter(); stop = threading.Event()

    workers = [threading.Thread(target=worker, args=(db, agg, stop))
               for _ in range(args.threads)]
    for t in workers: t.start()

    threading.Thread(target=reporter, args=(agg, stop), daemon=True).start()

    try:
        time.sleep(args.duration)
    finally:
        stop.set(); [t.join() for t in workers]
        fdb.stop_network(); net_thread.join()
        print("\nFinal totals:", agg)

if __name__ == "__main__":
    main()
